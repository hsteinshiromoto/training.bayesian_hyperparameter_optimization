{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Tunning XGBoost, Catboost and Lightgbm Classifiers Hyperparameters with Hyperopt"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Modules"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "source": [
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "from hyperopt import STATUS_FAIL, STATUS_OK, Trials, fmin, hp, tpe\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import f1_score, log_loss, roc_auc_score, get_scorer\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from xgboost import XGBClassifier\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "source": [
    "data = load_breast_cancer()\n",
    "X = data['data']\n",
    "y = data['target']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Preprocessing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=1, train_size=0.75)\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "# sss = StratifiedShuffleSplit(n_splits=1, train_size=0.9)\n",
    "# for train_index, val_index in sss.split(X, y):\n",
    "#     X_train, X_val = X[train_index], X[val_index]\n",
    "#     y_train, y_val = y[train_index], y[val_index]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup Estimators"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Some basic parameters:\n",
    "\n",
    "* `learning_rate` [X/L/C]: learning rate (alias: `eta` )\n",
    "* `max_depth` [X/L/C]: maximum depth of trees\n",
    "* `n_estimators` [X/L/C]: no. of boosting iterations\n",
    "* `min_child_weight` [X/L]: minimum sum of instance (hessian) weight needed in a child\n",
    "* `min_child_samples` [L/C]: minimum no. of data in one leaf\n",
    "* `subsample` [X/L/C]: subsample ratio of the training instances (note that for CatBoost this parameter can be used only if either Poisson or Bernoulli bootstrap_type is * `selected`)\n",
    "* `colsample_bytree` [X/L]: subsample ratio of columns in tree building\n",
    "* `colsample_bylevel` [X/C]: subsample ratio of columns for each level in tree building\n",
    "* `colsample_bynode` [X]: subsample ratio of columns for each node\n",
    "* `tree_method` [X]: tree construction method\n",
    "* `boosting` [L]: tree construction method\n",
    "* `boosting_type` [C]: Ordered for ordered boosting or Plain for classic\n",
    "* `early_stopping_rounds` [X/L/C]: parameter for fit() â€” stop the training if one metric of a validation data does not improve in last early_stopping_rounds rounds\n",
    "* `eval_metric` [X/L/C]: evaluation metrics for validation data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "source": [
    "hyperparameters = {\n",
    "    \"xgb_classifier\": {\n",
    "        'max_depth' : hp.randint('max_depth', 10),\n",
    "        'learning_rate' : hp.quniform('learning_rate', 0.01, 0.5, 0.01),\n",
    "        'n_estimators' : hp.randint('n_estimators', 250),\n",
    "        'gamma' : hp.quniform('gamma', 0, 0.50, 0.01),\n",
    "        'min_child_weight' : hp.quniform('min_child_weight', 1, 10, 1),\n",
    "        'subsample' : hp.quniform('subsample', 0.1, 1, 0.01),\n",
    "        'colsample_bytree' : hp.quniform('colsample_bytree', 0.1, 1.0, 0.01)\n",
    "        }\n",
    "\n",
    "    ,\"lgb_classifier\": {\n",
    "        'learning_rate':    hp.choice('learning_rate',    np.arange(0.05, 0.31, 0.05)),\n",
    "        'max_depth':        hp.choice('max_depth',        np.arange(5, 16, 1, dtype=int)),\n",
    "        'min_child_weight': hp.choice('min_child_weight', np.arange(1, 8, 1, dtype=int)),\n",
    "        'colsample_bytree': hp.choice('colsample_bytree', np.arange(0.3, 0.8, 0.1)),\n",
    "        'subsample':        hp.uniform('subsample', 0.8, 1),\n",
    "        'n_estimators':     100,\n",
    "    }\n",
    "\n",
    "    ,\"ctb_classifier\": {\n",
    "        'learning_rate':     hp.choice('learning_rate',     np.arange(0.05, 0.31, 0.05)),\n",
    "        'max_depth':         hp.choice('max_depth',         np.arange(5, 16, 1, dtype=int)),\n",
    "        'colsample_bylevel': hp.choice('colsample_bylevel', np.arange(0.3, 0.8, 0.1)),\n",
    "        'n_estimators':      100,\n",
    "    }\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "source": [
    "class select_estimator:\n",
    "    def __init__(self, X_train, X_val, y_train, y_val):\n",
    "        self.X = {\"train\": X_train, \"val\": X_val}\n",
    "        self.y = {\"train\": y_train, \"val\": y_val}\n",
    "        self.loss = {\"f1_score\": []\n",
    "                    ,\"log_loss\": []\n",
    "                    ,\"roc_auc_score\": []\n",
    "                    }\n",
    "        self.metrics = {\"f1_score\": f1_score\n",
    "                        ,\"log_loss\": log_loss\n",
    "                        ,\"roc_auc_score\": roc_auc_score\n",
    "                    }\n",
    "\n",
    "    def xgb_classifier(self, parameters):\n",
    "        estimator = XGBClassifier(**parameters, eval_metric=\"logloss\")\n",
    "        estimator.fit(self.X[\"train\"], self.y[\"train\"])\n",
    "        return self.get_loss(estimator)\n",
    "\n",
    "    def ctb_classifier(self, parameters):\n",
    "        estimator = CatBoostClassifier(**parameters)\n",
    "        estimator.fit(self.X[\"train\"], self.y[\"train\"])\n",
    "        return self.get_loss(estimator)\n",
    "\n",
    "    def lgb_classifier(self, parameters):\n",
    "        estimator = LGBMClassifier(**parameters)\n",
    "        estimator.fit(self.X[\"train\"], self.y[\"train\"])\n",
    "        return self.get_loss(estimator)\n",
    "\n",
    "    def process(self, fn_name, space, trials, algo, max_evals):\n",
    "        fn = getattr(self, fn_name)\n",
    "        try:\n",
    "            result = fmin(fn=fn, space=space, algo=algo, max_evals=max_evals, trials=trials)\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {'status': STATUS_FAIL,\n",
    "                    'exception': str(e)}\n",
    "\n",
    "        return result, trials\n",
    "\n",
    "\n",
    "    def get_loss(self, estimator):\n",
    "\n",
    "        for dataset_type, X in self.X.items():\n",
    "            y_pred_class = estimator.predict(X)\n",
    "            y_pred_proba = estimator.predict_proba(X)[:, 1]\n",
    "\n",
    "            for metric in self.loss.keys():\n",
    "                if metric in [\"f1_score\"]:\n",
    "                    self.loss[metric].append((1.0 - self.metrics[metric](self.y[dataset_type], y_pred_class))**2)\n",
    "\n",
    "                elif metric in [\"roc_auc_score\"]:\n",
    "                    self.loss[metric].append((1.0 - self.metrics[metric](self.y[dataset_type], y_pred_proba))**2)\n",
    "\n",
    "                elif metric in [\"log_loss\"]:\n",
    "                    self.loss[metric].append((self.metrics[metric](self.y[dataset_type], y_pred_class))**2)\n",
    "                \n",
    "        loss_df = pd.DataFrame.from_dict(self.loss)\n",
    "        loss = loss_df.sum(axis=0).sum()\n",
    "\n",
    "        return {'loss': np.sqrt(loss), 'status': STATUS_OK}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "source": [
    "obj = select_estimator(X_train, X_val, y_train, y_val)\n",
    "\n",
    "parameters = obj.process(fn_name='xgb_classifier', space=hyperparameters['xgb_classifier'], trials=Trials(), algo=tpe.suggest, max_evals=100)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Simple XGBoost"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "source": [
    "space = {\n",
    "        'max_depth' : hp.randint('max_depth', 10),\n",
    "        'learning_rate' : hp.quniform('learning_rate', 0.01, 0.5, 0.01),\n",
    "        'n_estimators' : hp.randint('n_estimators', 250),\n",
    "        'gamma' : hp.quniform('gamma', 0, 0.50, 0.01),\n",
    "        'min_child_weight' : hp.quniform('min_child_weight', 1, 10, 1),\n",
    "        'subsample' : hp.quniform('subsample', 0.1, 1, 0.01),\n",
    "        'colsample_bytree' : hp.quniform('colsample_bytree', 0.1, 1.0, 0.01)\n",
    "        }"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "source": [
    "def xgb_cost(space, X_train, y_train, X_val, y_val):\n",
    "\n",
    "    warnings.filterwarnings(action='ignore')\n",
    "\n",
    "    classifier = XGBClassifier(n_estimators = space['n_estimators']\n",
    "                            ,max_depth = int(space['max_depth'])\n",
    "                            ,learning_rate = space['learning_rate']\n",
    "                            ,gamma = space['gamma']\n",
    "                            ,min_child_weight = space['min_child_weight']\n",
    "                            ,subsample = space['subsample']\n",
    "                            ,colsample_bytree = space['colsample_bytree']\n",
    "                            ,use_label_encoder=False\n",
    "                            ,eval_metric=\"logloss\"\n",
    "                            )\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_proba_val = classifier.predict_proba(X_val)[:, 1]\n",
    "    y_class_val = classifier.predict(X_val)\n",
    "\n",
    "    rocauc_val = roc_auc_score(y_val, y_proba_val)\n",
    "    f1_val = f1_score(y_val, y_class_val)\n",
    "    logloss_val = log_loss(y_val, y_class_val)\n",
    "\n",
    "    y_proba_train = classifier.predict_proba(X_train)[:, 1]\n",
    "    y_class_train = classifier.predict(X_train)\n",
    "\n",
    "    # Applying k-Fold Cross Validation\n",
    "    rocauc_train = roc_auc_score(y_train, y_proba_train)\n",
    "    f1_train = f1_score(y_train, y_class_train)\n",
    "    logloss_train = log_loss(y_train, y_class_train)\n",
    "    \n",
    "    # print(f\"CrossValMean: {CrossValMean}\")\n",
    "    train_proportions = X_train.shape[0]/(X_train.shape[0] + X_val.shape[0])\n",
    "\n",
    "    loss = ((1.0 - rocauc_val)**2 + (1.0 - f1_val)**2 + logloss_val**2)/train_proportions\n",
    "    loss += ((1.0 - rocauc_train)**2 + (1.0 - f1_train)**2 + logloss_train**2)/(1-train_proportions)\n",
    "\n",
    "    return {'loss': np.sqrt(loss), 'status': STATUS_OK }"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "source": [
    "objective = lambda x: cost(x, X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "source": [
    "trials = Trials()\n",
    "\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=100,\n",
    "            trials=trials)\n",
    "\n",
    "print(\"Best: \", best)\n",
    "\n",
    " # Fitting XGBoost to the Training set\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:10<00:00,  9.55trial/s, best loss: 3.3280711111346004e-15]\n",
      "Best:  {'colsample_bytree': 0.38, 'gamma': 0.22, 'learning_rate': 0.45, 'max_depth': 9, 'min_child_weight': 1.0, 'n_estimators': 179, 'subsample': 0.65}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "source": [
    "best"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.38,\n",
       " 'gamma': 0.22,\n",
       " 'learning_rate': 0.45,\n",
       " 'max_depth': 9,\n",
       " 'min_child_weight': 1.0,\n",
       " 'n_estimators': 179,\n",
       " 'subsample': 0.65}"
      ]
     },
     "metadata": {},
     "execution_count": 228
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "source": [
    "classifier = XGBClassifier(**best)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    " \n",
    "\n",
    "# Applying k-Fold Cross Validation\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "\n",
    "CrossValMean = accuracies.mean()\n",
    "\n",
    "print(\"Final CrossValMean: \", CrossValMean)\n",
    "\n",
    " \n",
    "\n",
    "CrossValSTD = accuracies.std()\n",
    "\n",
    " \n",
    "\n",
    "# Predicting the Test set results\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "y_pred = pd.DataFrame(y_pred)\n",
    "\n",
    "y_pred.columns = ['Survived']\n",
    "\n",
    "submission = submission.join(y_pred)\n",
    "\n",
    " \n",
    "\n",
    "# Exporting dataset to csv\n",
    "\n",
    "submission.to_csv(\"Titanic_Submission.csv\", index=False, sep=',')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[14:05:23] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:05:23] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:05:23] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:05:23] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:05:23] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:05:23] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:05:23] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:05:23] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:05:23] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:05:23] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:05:23] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Final CrossValMean:  0.9628205128205127\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1408/1835188153.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Survived'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Bayes Search CV"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "source": [
    "import sys\n",
    "import traceback\n",
    "from abc import ABC, abstractmethod\n",
    "from collections.abc import Iterable\n",
    "from typing import Union\n",
    "\n",
    "from hyperopt import STATUS_FAIL, STATUS_OK, Trials, fmin, hp, tpe\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "class BayesSearchCV(ABC):\n",
    "\n",
    "    def __init__(self, estimator, param_distributions: dict, scoring: list[str]\n",
    "        ,n_iter: int=10, cv: Union[int, Iterable]=5, random_state: int=None\n",
    "        ,algo=tpe.suggest, trials: Trials=Trials()) -> None:\n",
    "        \"\"\"[summary]\n",
    "\n",
    "        Args:\n",
    "            estimator: Estimator object\n",
    "            param_distributions (dict): Search space containing hyperparameters\n",
    "            scoring (list[str]): List of performance metrics to measure the estimator performance.\n",
    "                                Select one from sklearn.metrics.SCORERS.keys()\n",
    "            n_iter (int, optional): Max number of iterations. Defaults to 10.\n",
    "            cv (int or Iterable, optional): int, cross-validation generator or an iterable. Defaults to 5.\n",
    "            random_state (int, optional): Pseudo random number generator state used for random uniform sampling. Defaults to None.\n",
    "            algo (optional): Algorithm to for distribution search. Defaults to tpe.suggest.\n",
    "            trials (Trials, optional): [description]. Defaults to Trials().\n",
    "        \"\"\"\n",
    "        self.estimator = estimator\n",
    "        self.param_distributions = param_distributions\n",
    "        self.n_iter = n_iter\n",
    "        self.random_state = random_state\n",
    "        self.cv = cv\n",
    "        self.algo = algo\n",
    "        self.trials = trials\n",
    "        self.scoring = scoring\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y=None):\n",
    "        \"\"\"Fit estimator with optimal hyperparameters\n",
    "\n",
    "        Args:\n",
    "            X (pd.DataFrame): Predictors\n",
    "            y (pd.DataFrame): Target\n",
    "        \"\"\"\n",
    "        self.cv_results_ = pd.DataFrame()\n",
    "        min_loss = np.inf\n",
    "\n",
    "        for train_index, val_index in self._get_splits(X, y):\n",
    "            X_train, X_val = X[train_index], X[val_index]\n",
    "            y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "            objective = lambda space: self._cost(X=X_train, y=y_train, hyperparameters=space)\n",
    "\n",
    "            try:\n",
    "                hyperparameters = fmin(fn=objective, space=self.param_distributions\n",
    "                            ,algo=self.algo, max_evals=self.n_iter\n",
    "                            ,trials=self.trials)\n",
    "\n",
    "            except KeyError:\n",
    "                exc_info = sys.exc_info()\n",
    "                traceback.print_exception(*exc_info)\n",
    "                return {'status': STATUS_FAIL,\n",
    "                        'exception': str(sys.exc_info())}\n",
    "\n",
    "            estimator, loss_df, loss = self._cost(X_val, y_val, hyperparameters, return_fit_estimator=True)\n",
    "\n",
    "            if loss < min_loss:\n",
    "                min_loss = loss\n",
    "                self.best_estimator_ = estimator\n",
    "\n",
    "            self.cv_results_ = pd.concat([self.cv_results_ , loss_df.copy()])\n",
    "\n",
    "        self.cv_results_.reset_index(inplace=True, drop=True)\n",
    "        self.cv_results_.rename(columns={col: f\"{col}_loss\" for col in self.cv_results_.columns}, inplace=True)\n",
    "\n",
    "\n",
    "    def _get_splits(self, X: pd.DataFrame, y=None):\n",
    "        \"\"\"Instantiate and/or get training and validation datasets\n",
    "\n",
    "        Args:\n",
    "            X (pd.DataFrame): Predictor\n",
    "            y (pd.DataFrame): Target\n",
    "\n",
    "        Returns:\n",
    "            [type]: [description]\n",
    "\n",
    "        Yields:\n",
    "            [type]: [description]\n",
    "        \"\"\"\n",
    "\n",
    "        if isinstance(self.cv, int): \n",
    "            self.cv = KFold(n_splits=self.cv, random_state=self.random_state)\n",
    "\n",
    "        elif isinstance(self.cv, StratifiedKFold):\n",
    "            pass\n",
    "\n",
    "        else:\n",
    "            msg = f\"Cross validation not yet implemented for type {type(self.cv)}\"\n",
    "            NotImplementedError(msg)\n",
    "            \n",
    "        for train_index, test_index in self.cv.split(X, y):\n",
    "            yield train_index, test_index\n",
    "\n",
    "\n",
    "    def _cost(self, X: pd.DataFrame, y: pd.DataFrame, hyperparameters: dict\n",
    "            ,return_fit_estimator: bool=False):\n",
    "        \"\"\"Evaluates the cost function for the trained estimator\n",
    "\n",
    "        Args:\n",
    "            X (pd.DataFrame): Predictor\n",
    "            y (pd.DataFrame): Target\n",
    "            hyperarameters (dict):\n",
    "        \"\"\"\n",
    "        estimator = self._instantiate_estimator(hyperparameters)\n",
    "\n",
    "        loss_dict = {metric_name: [] for metric_name in self.scoring}\n",
    "\n",
    "        estimator.fit(X, y)\n",
    "\n",
    "        for p_metric in self.scoring:\n",
    "            scorer = get_scorer(p_metric)\n",
    "            \n",
    "            if p_metric in [\"f1\"]:\n",
    "                loss_dict[p_metric].append((1.0 - scorer(estimator, X, y))**2)\n",
    "\n",
    "            elif p_metric in [\"roc_auc\"]:\n",
    "                loss_dict[p_metric].append((1.0 - scorer(estimator, X, y))**2)\n",
    "\n",
    "            elif p_metric in [\"neg_log_loss\"]:\n",
    "                loss_dict[p_metric].append((scorer(estimator, X, y))**2)\n",
    "\n",
    "            else:\n",
    "                msg = f\"Metric {p_metric} not implemented.\"\n",
    "                raise NotImplementedError(msg)\n",
    "\n",
    "        loss_df = pd.DataFrame.from_dict(loss_dict)\n",
    "        loss = loss_df.sum(axis=0).sum()\n",
    "\n",
    "        if return_fit_estimator:\n",
    "            return estimator, loss_df, loss\n",
    "\n",
    "        return {'loss': np.sqrt(loss), 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "\n",
    "    def _instantiate_estimator(self, hyperarameters: dict):\n",
    "        \"\"\"Instantiate estimator with selected hyperparameters\n",
    "\n",
    "        Args:\n",
    "            hyperarameters (dict):\n",
    "\n",
    "        Returns:\n",
    "            [type]: Estimator\n",
    "        \"\"\"\n",
    "        estimator_cls = self.estimator.__class__\n",
    "        return estimator_cls(**hyperarameters)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "source": [
    "space = {\n",
    "        'max_depth' : hp.randint('max_depth', 10),\n",
    "        'learning_rate' : hp.quniform('learning_rate', 0.01, 0.5, 0.01),\n",
    "        'n_estimators' : hp.randint('n_estimators', 250),\n",
    "        'gamma' : hp.quniform('gamma', 0, 0.50, 0.01),\n",
    "        'min_child_weight' : hp.quniform('min_child_weight', 1, 10, 1),\n",
    "        'subsample' : hp.quniform('subsample', 0.1, 1, 0.01),\n",
    "        'colsample_bytree' : hp.quniform('colsample_bytree', 0.1, 1.0, 0.01),\n",
    "        'eval_metric': \"logloss\"\n",
    "        }\n",
    "\n",
    "cv = BayesSearchCV(XGBClassifier(learning_rate=0.1), param_distributions=space, scoring=[\"roc_auc\", \"f1\"], cv=StratifiedKFold())\n",
    "cv.fit(X_train, y_train)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 18.44trial/s, best loss: 0.009360113324801356]\n",
      "[19:36:26] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<?, ?trial/s, best loss=?]\n",
      "[19:36:26] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<?, ?trial/s, best loss=?]\n",
      "[19:36:26] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<?, ?trial/s, best loss=?]\n",
      "[19:36:26] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<?, ?trial/s, best loss=?]\n",
      "[19:36:26] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "source": [
    "cv.cv_results_"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   roc_auc_loss   f1_loss\n",
       "0  1.013066e-05  0.000331\n",
       "1  6.030812e-05  0.000758\n",
       "2  3.128894e-06  0.000343\n",
       "3  3.476549e-07  0.000091\n",
       "4  8.691371e-08  0.000087"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roc_auc_loss</th>\n",
       "      <th>f1_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.013066e-05</td>\n",
       "      <td>0.000331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.030812e-05</td>\n",
       "      <td>0.000758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.128894e-06</td>\n",
       "      <td>0.000343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.476549e-07</td>\n",
       "      <td>0.000091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.691371e-08</td>\n",
       "      <td>0.000087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 592
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "source": [
    "cv.best_estimator_"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.55, gamma=0.28, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.26, max_delta_step=0, max_depth=9,\n",
       "              min_child_weight=6.0, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=93, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=0.99,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "metadata": {},
     "execution_count": 593
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "source": [
    "space = {\"lgb_classifier\": {\n",
    "        'learning_rate':    hp.choice('learning_rate',    np.arange(0.05, 0.31, 0.05)),\n",
    "        'max_depth':        hp.choice('max_depth',        np.arange(5, 16, 1, dtype=int)),\n",
    "        'min_child_weight': hp.choice('min_child_weight', np.arange(1, 8, 1, dtype=int)),\n",
    "        'colsample_bytree': hp.choice('colsample_bytree', np.arange(0.3, 0.8, 0.1)),\n",
    "        'subsample':        hp.uniform('subsample', 0.8, 1),\n",
    "        # 'n_estimators':     100,\n",
    "    }}\n",
    "cv = ClassifierBayesSearchCV(LGBMClassifier(), param_distributions=space, scoring=[\"roc_auc\", \"f1\"], cv=StratifiedKFold())\n",
    "cv.fit(X_train, y_train)\n",
    "# cv.best_estimator_"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<?, ?trial/s, best loss=?]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.41000000000000003,\n",
       " 'gamma': 0.32,\n",
       " 'learning_rate': 0.5,\n",
       " 'max_depth': 5,\n",
       " 'min_child_weight': 8.0,\n",
       " 'n_estimators': 137,\n",
       " 'subsample': 0.13}"
      ]
     },
     "metadata": {},
     "execution_count": 472
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "source": [
    "pm = sklearn.metrics.SCORERS[\"f1\"]\n",
    "pm()"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "__call__() missing 3 required positional arguments: 'estimator', 'X', and 'y_true'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1408/483979149.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSCORERS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"f1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __call__() missing 3 required positional arguments: 'estimator', 'X', and 'y_true'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "source": [
    "sorted(sklearn.metrics.SCORERS.keys())"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['accuracy',\n",
       " 'adjusted_mutual_info_score',\n",
       " 'adjusted_rand_score',\n",
       " 'average_precision',\n",
       " 'balanced_accuracy',\n",
       " 'completeness_score',\n",
       " 'explained_variance',\n",
       " 'f1',\n",
       " 'f1_macro',\n",
       " 'f1_micro',\n",
       " 'f1_samples',\n",
       " 'f1_weighted',\n",
       " 'fowlkes_mallows_score',\n",
       " 'homogeneity_score',\n",
       " 'jaccard',\n",
       " 'jaccard_macro',\n",
       " 'jaccard_micro',\n",
       " 'jaccard_samples',\n",
       " 'jaccard_weighted',\n",
       " 'max_error',\n",
       " 'mutual_info_score',\n",
       " 'neg_brier_score',\n",
       " 'neg_log_loss',\n",
       " 'neg_mean_absolute_error',\n",
       " 'neg_mean_absolute_percentage_error',\n",
       " 'neg_mean_gamma_deviance',\n",
       " 'neg_mean_poisson_deviance',\n",
       " 'neg_mean_squared_error',\n",
       " 'neg_mean_squared_log_error',\n",
       " 'neg_median_absolute_error',\n",
       " 'neg_root_mean_squared_error',\n",
       " 'normalized_mutual_info_score',\n",
       " 'precision',\n",
       " 'precision_macro',\n",
       " 'precision_micro',\n",
       " 'precision_samples',\n",
       " 'precision_weighted',\n",
       " 'r2',\n",
       " 'rand_score',\n",
       " 'recall',\n",
       " 'recall_macro',\n",
       " 'recall_micro',\n",
       " 'recall_samples',\n",
       " 'recall_weighted',\n",
       " 'roc_auc',\n",
       " 'roc_auc_ovo',\n",
       " 'roc_auc_ovo_weighted',\n",
       " 'roc_auc_ovr',\n",
       " 'roc_auc_ovr_weighted',\n",
       " 'top_k_accuracy',\n",
       " 'v_measure_score']"
      ]
     },
     "metadata": {},
     "execution_count": 517
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "source": [
    "get_scorer(\"f1_score\")"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "'f1_score' is not a valid scoring value. Use sorted(sklearn.metrics.SCORERS.keys()) to get valid options.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36mget_scorer\u001b[0;34m(scoring)\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m             \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSCORERS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'f1_score'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1408/1040153200.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_scorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"f1_score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36mget_scorer\u001b[0;34m(scoring)\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSCORERS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             raise ValueError('%r is not a valid scoring value. '\n\u001b[0m\u001b[1;32m    388\u001b[0m                              \u001b[0;34m'Use sorted(sklearn.metrics.SCORERS.keys()) '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m                              'to get valid options.' % scoring)\n",
      "\u001b[0;31mValueError\u001b[0m: 'f1_score' is not a valid scoring value. Use sorted(sklearn.metrics.SCORERS.keys()) to get valid options."
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "source": [
    "module = __import__()\n",
    "class_ = getattr(module, model.__class__.__name__)\n",
    "instance = class_()"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'XGBClassifier'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1408/2043593128.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__import__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mclass_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0minstance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'XGBClassifier'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "source": [
    "a = XGBClassifier(learning_rate=0.1, eval_metric=\"logloss\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}